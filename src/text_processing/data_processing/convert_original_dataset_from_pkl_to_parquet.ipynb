{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2a017d4",
   "metadata": {},
   "source": [
    "## Setting up paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04b3feaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base dir: /Users/arthur/Desktop/Hackathon-FIAM-2025\n",
      "Dataset dir: /Users/arthur/Desktop/Hackathon-FIAM-2025/src/text_processing/dataset\n",
      "Dataset output file: /Users/arthur/Desktop/Hackathon-FIAM-2025/src/text_processing/dataset/dataset.parquet\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# dans un notebook : utilise cwd\n",
    "BASE_DIR = Path.cwd().parents[2]\n",
    "DATASET_DIR = BASE_DIR / \"src\" / \"text_processing\" / \"dataset\"\n",
    "DATASET_OUTPUT_FILE = DATASET_DIR / \"dataset.parquet\"\n",
    "\n",
    "print(\"Base dir:\", BASE_DIR)\n",
    "print(\"Dataset dir:\", DATASET_DIR)\n",
    "print(\"Dataset output file:\", DATASET_OUTPUT_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd016ace",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f33dd0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = 2005\n",
    "end_date = 2025\n",
    "delete_after = True\n",
    "ignore_warnings = True\n",
    "export_to_parquet = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc79663",
   "metadata": {},
   "source": [
    "## Importing Libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ed6c755",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle as pkl\n",
    "import polars as pl\n",
    "import gc\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0840fd6",
   "metadata": {},
   "source": [
    "## Messing with warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d8c8e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignorer tous les DeprecationWarning de la fonction load_datasets_polars\n",
    "if ignore_warnings == True:\n",
    "    warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc3b063b",
   "metadata": {},
   "source": [
    "## Load dataset converter function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8517ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle as pkl\n",
    "import polars as pl\n",
    "import gc\n",
    "\n",
    "def load_datasets_polars(\n",
    "    path: str = \"./dataset\",\n",
    "    start_date: int = 2005,\n",
    "    end_date: int = 2025,\n",
    "    out_file: str = \"./dataset/text_us.parquet\"\n",
    ") -> pl.DataFrame:\n",
    "    if not os.path.isdir(path):\n",
    "        raise FileNotFoundError(f\"Dataset folder not found: {path}\")\n",
    "\n",
    "    df_all = None  # initialisation vide\n",
    "    total_rows = 0  # compteur de lignes cumulées\n",
    "\n",
    "    for year in range(start_date, end_date + 1):\n",
    "        file_path = os.path.join(path, f\"text_us_{year}.pkl\")\n",
    "        try:\n",
    "            with open(file_path, \"rb\") as f:\n",
    "                df = pkl.load(f)  # pandas DataFrame\n",
    "            df[\"year\"] = year\n",
    "            df_polars = pl.from_pandas(df)\n",
    "            del df\n",
    "            gc.collect()\n",
    "\n",
    "            # compteur de lignes\n",
    "            total_rows += df_polars.height\n",
    "            print(f\"[OK] Loaded text_us_{year}.pkl ({df_polars.height} lignes, cumul={total_rows})\")\n",
    "\n",
    "            if df_all is None:\n",
    "                df_all = df_polars\n",
    "            else:\n",
    "                df_all = pl.concat([df_all, df_polars], how=\"vertical\")\n",
    "\n",
    "        except FileNotFoundError:\n",
    "            raise FileNotFoundError(f\"Missing dataset for year {year}: {file_path}\")\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(f\"Error loading {file_path}: {e}\")\n",
    "\n",
    "    # écriture parquet\n",
    "\n",
    "    # comparaison sanity check\n",
    "    print(f\"\\n[ℹ️] Compteur de lignes cumulées : {total_rows}\")\n",
    "    print(f\"[ℹ️] Nombre de lignes dans df_all : {df_all.height}\")\n",
    "\n",
    "    if total_rows == df_all.height:\n",
    "        print(\"[✅] Les deux comptes correspondent, concat ok.\")\n",
    "    else:\n",
    "        print(\"[⚠️] Attention : mismatch détecté !\")\n",
    "\n",
    "\n",
    "\n",
    "    return df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0ec6134",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Loaded text_us_2005.pkl (16857 lignes, cumul=16857)\n",
      "[OK] Loaded text_us_2006.pkl (16553 lignes, cumul=33410)\n",
      "[OK] Loaded text_us_2007.pkl (16875 lignes, cumul=50285)\n",
      "[OK] Loaded text_us_2008.pkl (18391 lignes, cumul=68676)\n",
      "[OK] Loaded text_us_2009.pkl (18133 lignes, cumul=86809)\n",
      "[OK] Loaded text_us_2010.pkl (17537 lignes, cumul=104346)\n",
      "[OK] Loaded text_us_2011.pkl (17398 lignes, cumul=121744)\n",
      "[OK] Loaded text_us_2012.pkl (16968 lignes, cumul=138712)\n",
      "[OK] Loaded text_us_2013.pkl (17401 lignes, cumul=156113)\n",
      "[OK] Loaded text_us_2014.pkl (17814 lignes, cumul=173927)\n",
      "[OK] Loaded text_us_2015.pkl (17514 lignes, cumul=191441)\n",
      "[OK] Loaded text_us_2016.pkl (16840 lignes, cumul=208281)\n",
      "[OK] Loaded text_us_2017.pkl (16424 lignes, cumul=224705)\n",
      "[OK] Loaded text_us_2018.pkl (16326 lignes, cumul=241031)\n",
      "[OK] Loaded text_us_2019.pkl (16222 lignes, cumul=257253)\n",
      "[OK] Loaded text_us_2020.pkl (16335 lignes, cumul=273588)\n",
      "[OK] Loaded text_us_2021.pkl (17318 lignes, cumul=290906)\n",
      "[OK] Loaded text_us_2022.pkl (17703 lignes, cumul=308609)\n",
      "[OK] Loaded text_us_2023.pkl (17834 lignes, cumul=326443)\n",
      "[OK] Loaded text_us_2024.pkl (20352 lignes, cumul=346795)\n",
      "[OK] Loaded text_us_2025.pkl (11644 lignes, cumul=358439)\n",
      "\n",
      "[ℹ️] Compteur de lignes cumulées : 358439\n",
      "[ℹ️] Nombre de lignes dans df_all : 358439\n",
      "[✅] Les deux comptes correspondent, concat ok.\n",
      "Loaded datasets:\n"
     ]
    }
   ],
   "source": [
    "df = load_datasets_polars(path=DATASET_DIR, start_date=2005, \n",
    "                          end_date=2025, out_file=DATASET_OUTPUT_FILE)\n",
    "print(\"Loaded datasets:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e2d637",
   "metadata": {},
   "source": [
    "## Export dataset to parquet file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eba6dc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to export dataset to parquet\n",
      "[✅] Exported dataset to /Users/arthur/Desktop/Hackathon-FIAM-2025/src/text_processing/dataset/dataset.parquet\n"
     ]
    }
   ],
   "source": [
    "if export_to_parquet == True:\n",
    "    print(\"Starting to export dataset to parquet\") # C'est un peu long env 5 minutes\n",
    "    df.write_parquet(DATASET_OUTPUT_FILE)\n",
    "    print(f\"[✅] Exported dataset to {DATASET_OUTPUT_FILE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e3daf3",
   "metadata": {},
   "source": [
    "## Dataset verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ec7cb772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (20, 8)\n",
      "┌──────────┬─────────┬───────────┬─────┬─────────────────────────────┬──────────┬───────────┬──────┐\n",
      "│ date     ┆ cik     ┆ file_type ┆ rf  ┆ mgmt                        ┆ gvkey    ┆ cusip     ┆ year │\n",
      "│ ---      ┆ ---     ┆ ---       ┆ --- ┆ ---                         ┆ ---      ┆ ---       ┆ ---  │\n",
      "│ str      ┆ i64     ┆ str       ┆ str ┆ str                         ┆ f64      ┆ str       ┆ i64  │\n",
      "╞══════════╪═════════╪═══════════╪═════╪═════════════════════════════╪══════════╪═══════════╪══════╡\n",
      "│ 20050103 ┆ 16099   ┆ 10Q       ┆     ┆ Item 2 Management s         ┆ 6831.0   ┆ 549282101 ┆ 2005 │\n",
      "│          ┆         ┆           ┆     ┆ Discussion…                 ┆          ┆           ┆      │\n",
      "│ 20050103 ┆ 779544  ┆ 10K       ┆     ┆ Item 7. Management's        ┆ 11872.0  ┆ 040712101 ┆ 2005 │\n",
      "│          ┆         ┆           ┆     ┆ Discussio…                  ┆          ┆           ┆      │\n",
      "│ 20050103 ┆ 831641  ┆ 10K       ┆     ┆ Item 7                      ┆ 24783.0  ┆ 88162G103 ┆ 2005 │\n",
      "│          ┆         ┆           ┆     ┆                             ┆          ┆           ┆      │\n",
      "│          ┆         ┆           ┆     ┆  Management's Discus…       ┆          ┆           ┆      │\n",
      "│ 20050103 ┆ 866415  ┆ 10K       ┆     ┆ ITEM 7. Management's        ┆ 61721.0  ┆ 459412102 ┆ 2005 │\n",
      "│          ┆         ┆           ┆     ┆ Discussio…                  ┆          ┆           ┆      │\n",
      "│ 20050103 ┆ 1141240 ┆ 10Q       ┆     ┆ Item                        ┆ 146117.0 ┆ 53634X100 ┆ 2005 │\n",
      "│          ┆         ┆           ┆     ┆  2 Management s Discussio…  ┆          ┆           ┆      │\n",
      "│ …        ┆ …       ┆ …         ┆ …   ┆ …                           ┆ …        ┆ …         ┆ …    │\n",
      "│ 20050105 ┆ 835541  ┆ 10Q       ┆     ┆ Item 2. Management s        ┆ 17110.0  ┆ 834182107 ┆ 2005 │\n",
      "│          ┆         ┆           ┆     ┆ Discussio…                  ┆          ┆           ┆      │\n",
      "│ 20050105 ┆ 857323  ┆ 10Q       ┆     ┆ Item 2. Management's        ┆ 25807.0  ┆ 400518106 ┆ 2005 │\n",
      "│          ┆         ┆           ┆     ┆ Discussio…                  ┆          ┆           ┆      │\n",
      "│ 20050105 ┆ 1050825 ┆ 10Q       ┆     ┆ Item 2.                     ┆ 66290.0  ┆ 858155203 ┆ 2005 │\n",
      "│          ┆         ┆           ┆     ┆                             ┆          ┆           ┆      │\n",
      "│          ┆         ┆           ┆     ┆ Management s Discuss…       ┆          ┆           ┆      │\n",
      "│ 20050106 ┆ 23217   ┆ 10Q       ┆     ┆ Item 2.                     ┆ 3362.0   ┆ 205887102 ┆ 2005 │\n",
      "│          ┆         ┆           ┆     ┆ Management s Discussi…      ┆          ┆           ┆      │\n",
      "│ 20050106 ┆ 33619   ┆ 10K       ┆     ┆ Item 7. Management s        ┆ 4460.0   ┆ 297425100 ┆ 2005 │\n",
      "│          ┆         ┆           ┆     ┆ Discussio…                  ┆          ┆           ┆      │\n",
      "└──────────┴─────────┴───────────┴─────┴─────────────────────────────┴──────────┴───────────┴──────┘\n"
     ]
    }
   ],
   "source": [
    "print(df.head(20))    # head 20 first lines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23169845",
   "metadata": {},
   "source": [
    "## Empty RAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "590ddbed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset successfully released from memory.\n"
     ]
    }
   ],
   "source": [
    "if delete_after == True:\n",
    "    del df\n",
    "    print(\"Dataset successfully released from memory.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ECN6338",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
