{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59c228e0",
   "metadata": {},
   "source": [
    "# ğŸ“Œ Dataset Preparation (Step 1)\n",
    "\n",
    "This notebook is dedicated to **preparing the dataset** for further analysis and modeling.  \n",
    "\n",
    "### ğŸ”¹ What it does\n",
    "- Loads yearly `.pkl` files (`text_us_{year}.pkl`) stored in  \n",
    "  `src/text_processing/text_dataset/`\n",
    "- Merges them into a single Polars DataFrame\n",
    "- Adds a `year` column for reference\n",
    "- Sanity check: validates row counts after concatenation\n",
    "- Exports the final dataset into one file:  \n",
    "  `text_dataset.parquet` (âš ï¸ ~5 minutes to write)\n",
    "- Optional cleanup: deletes the dataset from memory once exported  \n",
    "\n",
    "### ğŸ”¹ Parameters\n",
    "- `start_date` = **2005**  \n",
    "- `end_date` = **2025**  \n",
    "- `delete_after = True` â†’ free RAM after export  \n",
    "- `ignore_warnings = True` â†’ silence `DeprecationWarning`  \n",
    "- `export_to_parquet = True` â†’ save merged dataset  \n",
    "\n",
    "---\n",
    "\n",
    "ğŸ‘‰ After this step, your dataset is **consolidated and ready** to be used in the next notebooks (feature engineering, modeling, etc.)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a017d4",
   "metadata": {},
   "source": [
    "## Setting up paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04b3feaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base dir: /Users/arthur/Desktop/Hackathon-FIAM-2025\n",
      "Dataset dir: /Users/arthur/Desktop/Hackathon-FIAM-2025/src/text_processing/text_dataset\n",
      "Dataset output file: /Users/arthur/Desktop/Hackathon-FIAM-2025/src/text_processing/text_dataset/text_dataset.parquet\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "\n",
    "BASE_DIR = Path.cwd().parents[2]\n",
    "DATASET_DIR = BASE_DIR / \"src\" / \"text_processing\" / \"text_dataset\"\n",
    "DATASET_OUTPUT_FILE = DATASET_DIR / \"text_dataset.parquet\"\n",
    "\n",
    "print(\"Base dir:\", BASE_DIR)\n",
    "print(\"Dataset dir:\", DATASET_DIR)\n",
    "print(\"Dataset output file:\", DATASET_OUTPUT_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd016ace",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f33dd0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = 2005\n",
    "end_date = 2025\n",
    "delete_after = True\n",
    "ignore_warnings = True\n",
    "export_to_parquet = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc79663",
   "metadata": {},
   "source": [
    "## Importing Libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ed6c755",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle as pkl\n",
    "import polars as pl\n",
    "import gc\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0840fd6",
   "metadata": {},
   "source": [
    "## Messing with warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d8c8e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppress DeprecationWarnings during dataset loading\n",
    "if ignore_warnings == True:\n",
    "    warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc3b063b",
   "metadata": {},
   "source": [
    "## Load dataset converter function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8517ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle as pkl\n",
    "import polars as pl\n",
    "import gc\n",
    "\n",
    "def load_datasets_polars(\n",
    "    path: str = \"./dataset\",\n",
    "    start_date: int = 2005,\n",
    "    end_date: int = 2025,\n",
    "    out_file: str = \"./dataset/text_us.parquet\"\n",
    ") -> pl.DataFrame:\n",
    "    \n",
    "    if not os.path.isdir(path):\n",
    "        raise FileNotFoundError(f\"Dataset folder not found: {path}\")\n",
    "\n",
    "    df_all = None  # empty df init\n",
    "    total_rows = 0  # Cumulative row counter\n",
    "\n",
    "    for year in range(start_date, end_date + 1):\n",
    "        file_path = os.path.join(path, f\"text_us_{year}.pkl\")\n",
    "        try:\n",
    "            with open(file_path, \"rb\") as f:\n",
    "                df = pkl.load(f)  # Pandas DataFrame\n",
    "            df[\"year\"] = year\n",
    "            df_polars = pl.from_pandas(df)\n",
    "            del df\n",
    "            gc.collect()\n",
    "\n",
    "            # Row counter\n",
    "            total_rows += df_polars.height\n",
    "            print(f\"[OK] Loaded text_us_{year}.pkl ({df_polars.height} lignes, cumul={total_rows})\")\n",
    "\n",
    "            if df_all is None:\n",
    "                df_all = df_polars\n",
    "            else:\n",
    "                df_all = pl.concat([df_all, df_polars], how=\"vertical\")\n",
    "\n",
    "        except FileNotFoundError:\n",
    "            raise FileNotFoundError(f\"Missing dataset for year {year}: {file_path}\")\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(f\"Error loading {file_path}: {e}\")\n",
    "\n",
    "    # Sanity check: compare row counts\n",
    "    print(f\"\\n[â„¹ï¸] Compteur de lignes cumulÃ©es : {total_rows}\")\n",
    "    print(f\"[â„¹ï¸] Nombre de lignes dans df_all : {df_all.height}\")\n",
    "\n",
    "    if total_rows == df_all.height:\n",
    "        print(\"[âœ…] Les deux comptes correspondent, concat ok.\")\n",
    "    else:\n",
    "        print(\"[âš ï¸] Attention : mismatch dÃ©tectÃ© !\")\n",
    "\n",
    "\n",
    "\n",
    "    return df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0ec6134",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Loaded text_us_2005.pkl (16857 lignes, cumul=16857)\n",
      "[OK] Loaded text_us_2006.pkl (16553 lignes, cumul=33410)\n",
      "[OK] Loaded text_us_2007.pkl (16875 lignes, cumul=50285)\n",
      "[OK] Loaded text_us_2008.pkl (18391 lignes, cumul=68676)\n",
      "[OK] Loaded text_us_2009.pkl (18133 lignes, cumul=86809)\n",
      "[OK] Loaded text_us_2010.pkl (17537 lignes, cumul=104346)\n",
      "[OK] Loaded text_us_2011.pkl (17398 lignes, cumul=121744)\n",
      "[OK] Loaded text_us_2012.pkl (16968 lignes, cumul=138712)\n",
      "[OK] Loaded text_us_2013.pkl (17401 lignes, cumul=156113)\n",
      "[OK] Loaded text_us_2014.pkl (17814 lignes, cumul=173927)\n",
      "[OK] Loaded text_us_2015.pkl (17514 lignes, cumul=191441)\n",
      "[OK] Loaded text_us_2016.pkl (16840 lignes, cumul=208281)\n",
      "[OK] Loaded text_us_2017.pkl (16424 lignes, cumul=224705)\n",
      "[OK] Loaded text_us_2018.pkl (16326 lignes, cumul=241031)\n",
      "[OK] Loaded text_us_2019.pkl (16222 lignes, cumul=257253)\n",
      "[OK] Loaded text_us_2020.pkl (16335 lignes, cumul=273588)\n",
      "[OK] Loaded text_us_2021.pkl (17318 lignes, cumul=290906)\n",
      "[OK] Loaded text_us_2022.pkl (17703 lignes, cumul=308609)\n",
      "[OK] Loaded text_us_2023.pkl (17834 lignes, cumul=326443)\n",
      "[OK] Loaded text_us_2024.pkl (20352 lignes, cumul=346795)\n",
      "[OK] Loaded text_us_2025.pkl (11644 lignes, cumul=358439)\n",
      "\n",
      "[â„¹ï¸] Compteur de lignes cumulÃ©es : 358439\n",
      "[â„¹ï¸] Nombre de lignes dans df_all : 358439\n",
      "[âœ…] Les deux comptes correspondent, concat ok.\n",
      "Loaded datasets:\n"
     ]
    }
   ],
   "source": [
    "df = load_datasets_polars(path=DATASET_DIR, start_date=2005, \n",
    "                          end_date=2025, out_file=DATASET_OUTPUT_FILE)\n",
    "print(\"Loaded datasets:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e2d637",
   "metadata": {},
   "source": [
    "## Export dataset to parquet file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6eba6dc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to export dataset to parquet\n",
      "[âœ…] Exported dataset to /Users/arthur/Desktop/Hackathon-FIAM-2025/src/text_processing/text_dataset/text_dataset.parquet\n"
     ]
    }
   ],
   "source": [
    "if export_to_parquet == True:\n",
    "    print(\"Starting to export dataset to parquet\") # Takes about 5 minutes\n",
    "    df.write_parquet(DATASET_OUTPUT_FILE)\n",
    "    print(f\"[âœ…] Exported dataset to {DATASET_OUTPUT_FILE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e3daf3",
   "metadata": {},
   "source": [
    "## Dataset verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ec7cb772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (20, 8)\n",
      "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”\n",
      "â”‚ date     â”† cik     â”† file_type â”† rf  â”† mgmt                        â”† gvkey    â”† cusip     â”† year â”‚\n",
      "â”‚ ---      â”† ---     â”† ---       â”† --- â”† ---                         â”† ---      â”† ---       â”† ---  â”‚\n",
      "â”‚ str      â”† i64     â”† str       â”† str â”† str                         â”† f64      â”† str       â”† i64  â”‚\n",
      "â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•¡\n",
      "â”‚ 20050103 â”† 16099   â”† 10Q       â”†     â”† Item 2 Management s         â”† 6831.0   â”† 549282101 â”† 2005 â”‚\n",
      "â”‚          â”†         â”†           â”†     â”† Discussionâ€¦                 â”†          â”†           â”†      â”‚\n",
      "â”‚ 20050103 â”† 779544  â”† 10K       â”†     â”† Item 7. Management's        â”† 11872.0  â”† 040712101 â”† 2005 â”‚\n",
      "â”‚          â”†         â”†           â”†     â”† Discussioâ€¦                  â”†          â”†           â”†      â”‚\n",
      "â”‚ 20050103 â”† 831641  â”† 10K       â”†     â”† Item 7                      â”† 24783.0  â”† 88162G103 â”† 2005 â”‚\n",
      "â”‚          â”†         â”†           â”†     â”†                             â”†          â”†           â”†      â”‚\n",
      "â”‚          â”†         â”†           â”†     â”†  Management's Discusâ€¦       â”†          â”†           â”†      â”‚\n",
      "â”‚ 20050103 â”† 866415  â”† 10K       â”†     â”† ITEM 7. Management's        â”† 61721.0  â”† 459412102 â”† 2005 â”‚\n",
      "â”‚          â”†         â”†           â”†     â”† Discussioâ€¦                  â”†          â”†           â”†      â”‚\n",
      "â”‚ 20050103 â”† 1141240 â”† 10Q       â”†     â”† Item                        â”† 146117.0 â”† 53634X100 â”† 2005 â”‚\n",
      "â”‚          â”†         â”†           â”†     â”†  2 Management s Discussioâ€¦  â”†          â”†           â”†      â”‚\n",
      "â”‚ â€¦        â”† â€¦       â”† â€¦         â”† â€¦   â”† â€¦                           â”† â€¦        â”† â€¦         â”† â€¦    â”‚\n",
      "â”‚ 20050105 â”† 835541  â”† 10Q       â”†     â”† Item 2. Management s        â”† 17110.0  â”† 834182107 â”† 2005 â”‚\n",
      "â”‚          â”†         â”†           â”†     â”† Discussioâ€¦                  â”†          â”†           â”†      â”‚\n",
      "â”‚ 20050105 â”† 857323  â”† 10Q       â”†     â”† Item 2. Management's        â”† 25807.0  â”† 400518106 â”† 2005 â”‚\n",
      "â”‚          â”†         â”†           â”†     â”† Discussioâ€¦                  â”†          â”†           â”†      â”‚\n",
      "â”‚ 20050105 â”† 1050825 â”† 10Q       â”†     â”† Item 2.                     â”† 66290.0  â”† 858155203 â”† 2005 â”‚\n",
      "â”‚          â”†         â”†           â”†     â”†                             â”†          â”†           â”†      â”‚\n",
      "â”‚          â”†         â”†           â”†     â”† Management s Discussâ€¦       â”†          â”†           â”†      â”‚\n",
      "â”‚ 20050106 â”† 23217   â”† 10Q       â”†     â”† Item 2.                     â”† 3362.0   â”† 205887102 â”† 2005 â”‚\n",
      "â”‚          â”†         â”†           â”†     â”† Management s Discussiâ€¦      â”†          â”†           â”†      â”‚\n",
      "â”‚ 20050106 â”† 33619   â”† 10K       â”†     â”† Item 7. Management s        â”† 4460.0   â”† 297425100 â”† 2005 â”‚\n",
      "â”‚          â”†         â”†           â”†     â”† Discussioâ€¦                  â”†          â”†           â”†      â”‚\n",
      "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”˜\n"
     ]
    }
   ],
   "source": [
    "print(df.head(20))    # Head 20 first lines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23169845",
   "metadata": {},
   "source": [
    "## Empty RAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "590ddbed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset successfully released from memory.\n"
     ]
    }
   ],
   "source": [
    "if delete_after == True:\n",
    "    del df\n",
    "    print(\"Dataset successfully released from memory.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ECN6338",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
